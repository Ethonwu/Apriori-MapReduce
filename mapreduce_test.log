INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1607729131_0001 failed with state FAILED due to: NA
INFO main org.apache.hadoop.mapreduce.Job - Counters: 0
WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobSubmitter - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local70790799_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO Thread-11 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local70790799_0001
INFO Thread-11 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-11 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local70790799_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/ethonwu/Output.txt:0+76
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO Thread-11 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
WARN Thread-11 org.apache.hadoop.mapred.LocalJobRunner - job_local70790799_0001
java.lang.Exception: java.lang.Error: Unresolved compilation problem: 
	The method write(Text, IntWritable) in the type TaskInputOutputContext<Object,Text,Text,IntWritable> is not applicable for the arguments (Text, String)

	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.Error: Unresolved compilation problem: 
	The method write(Text, IntWritable) in the type TaskInputOutputContext<Object,Text,Text,IntWritable> is not applicable for the arguments (Text, String)

	at Apriori.Apriori$TokenizerMapper.map(Apriori.java:101)
	at Apriori.Apriori$TokenizerMapper.map(Apriori.java:1)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:145)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:784)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
INFO main org.apache.hadoop.mapreduce.Job - Job job_local70790799_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local70790799_0001 failed with state FAILED due to: NA
INFO main org.apache.hadoop.mapreduce.Job - Counters: 0
WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobSubmitter - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local205002201_0001
INFO Thread-11 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local205002201_0001
INFO Thread-11 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-11 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local205002201_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/ethonwu/Output.txt:0+76
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 745; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local205002201_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local205002201_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local205002201_0001_m_000000_0
INFO Thread-11 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-11 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local205002201_0001_r_000000_0
INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@255312ce
INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local205002201_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local205002201_0001_m_000000_0 decomp: 847 len: 851 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 847 bytes from map-output for attempt_local205002201_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 847, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->847
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 844 bytes
INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 847 bytes to disk to satisfy reduce memory limit
INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 851 bytes from disk
INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 844 bytes
INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local205002201_0001_r_000000_0 is done. And is in the process of committing
INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local205002201_0001_r_000000_0 is allowed to commit now
INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local205002201_0001_r_000000_0' to hdfs://localhost:9000/ethonwu/output/_temporary/0/task_local205002201_0001_r_000000
INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local205002201_0001_r_000000_0' done.
INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local205002201_0001_r_000000_0
INFO Thread-11 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job - Job job_local205002201_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local205002201_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=2060
		FILE: Number of bytes written=509339
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1242
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=23
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=5
		Map output records=50
		Map output bytes=745
		Map output materialized bytes=851
		Input split bytes=105
		Combine input records=0
		Combine output records=0
		Reduce input groups=7
		Reduce shuffle bytes=851
		Reduce input records=50
		Reduce output records=0
		Spilled Records=100
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=617611264
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=76
	File Output Format Counters 
		Bytes Written=0
WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobSubmitter - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1908997123_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1908997123_0001
INFO Thread-11 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-11 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-11 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1908997123_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/ethonwu/Output.txt:0+76
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 745; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1908997123_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1908997123_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1908997123_0001_m_000000_0
INFO Thread-11 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-11 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1908997123_0001_r_000000_0
INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@255312ce
INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1908997123_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1908997123_0001_m_000000_0 decomp: 847 len: 851 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 847 bytes from map-output for attempt_local1908997123_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 847, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->847
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 844 bytes
INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 847 bytes to disk to satisfy reduce memory limit
INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 851 bytes from disk
INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 844 bytes
INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1908997123_0001_r_000000_0 is done. And is in the process of committing
INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1908997123_0001_r_000000_0 is allowed to commit now
INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1908997123_0001_r_000000_0' to hdfs://localhost:9000/ethonwu/output/_temporary/0/task_local1908997123_0001_r_000000
INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1908997123_0001_r_000000_0' done.
INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1908997123_0001_r_000000_0
INFO Thread-11 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1908997123_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1908997123_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=2060
		FILE: Number of bytes written=513051
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1242
		HDFS: Number of bytes written=100
		HDFS: Number of read operations=23
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=5
		Map output records=50
		Map output bytes=745
		Map output materialized bytes=851
		Input split bytes=105
		Combine input records=0
		Combine output records=0
		Reduce input groups=7
		Reduce shuffle bytes=851
		Reduce input records=50
		Reduce output records=7
		Spilled Records=100
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=4
		Total committed heap usage (bytes)=543162368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=76
	File Output Format Counters 
		Bytes Written=100
WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobSubmitter - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local189628285_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local189628285_0001
INFO Thread-11 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-11 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-11 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local189628285_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/ethonwu/Output.txt:0+76
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 745; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214200(104856800); length = 197/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local189628285_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local189628285_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local189628285_0001_m_000000_0
INFO Thread-11 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-11 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local189628285_0001_r_000000_0
INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@73c5c6ad
INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local189628285_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local189628285_0001_m_000000_0 decomp: 847 len: 851 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 847 bytes from map-output for attempt_local189628285_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 847, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->847
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 844 bytes
INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 847 bytes to disk to satisfy reduce memory limit
INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 851 bytes from disk
INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 844 bytes
INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local189628285_0001_r_000000_0 is done. And is in the process of committing
INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local189628285_0001_r_000000_0 is allowed to commit now
INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local189628285_0001_r_000000_0' to hdfs://localhost:9000/ethonwu/output/_temporary/0/task_local189628285_0001_r_000000
INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local189628285_0001_r_000000_0' done.
INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local189628285_0001_r_000000_0
INFO Thread-11 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job - Job job_local189628285_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local189628285_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=2060
		FILE: Number of bytes written=509339
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1242
		HDFS: Number of bytes written=85
		HDFS: Number of read operations=23
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=5
		Map output records=50
		Map output bytes=745
		Map output materialized bytes=851
		Input split bytes=105
		Combine input records=0
		Combine output records=0
		Reduce input groups=7
		Reduce shuffle bytes=851
		Reduce input records=50
		Reduce output records=7
		Spilled Records=100
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=8
		Total committed heap usage (bytes)=510132224
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=76
	File Output Format Counters 
		Bytes Written=85
WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobSubmitter - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local426071901_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO Thread-11 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-11 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local426071901_0001
INFO Thread-11 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local426071901_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/ethonwu/Output.txt:0+76
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 8725; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26211584(104846336); length = 2813/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local426071901_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local426071901_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local426071901_0001_m_000000_0
INFO Thread-11 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-11 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local426071901_0001_r_000000_0
INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@472560d
INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local426071901_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local426071901_0001_m_000000_0 decomp: 10135 len: 10139 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 10135 bytes from map-output for attempt_local426071901_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 10135, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->10135
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 10132 bytes
INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 10135 bytes to disk to satisfy reduce memory limit
INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 10139 bytes from disk
INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 10132 bytes
INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local426071901_0001_r_000000_0 is done. And is in the process of committing
INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local426071901_0001_r_000000_0 is allowed to commit now
INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local426071901_0001_r_000000_0' to hdfs://localhost:9000/ethonwu/output/_temporary/0/task_local426071901_0001_r_000000
INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local426071901_0001_r_000000_0' done.
INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local426071901_0001_r_000000_0
INFO Thread-11 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job - Job job_local426071901_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local426071901_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=20636
		FILE: Number of bytes written=537203
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1242
		HDFS: Number of bytes written=73
		HDFS: Number of read operations=23
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=5
		Map output records=704
		Map output bytes=8725
		Map output materialized bytes=10139
		Input split bytes=105
		Combine input records=0
		Combine output records=0
		Reduce input groups=626
		Reduce shuffle bytes=10139
		Reduce input records=704
		Reduce output records=19
		Spilled Records=1408
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=16
		Total committed heap usage (bytes)=548405248
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=76
	File Output Format Counters 
		Bytes Written=73
WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobSubmitter - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local439872970_0001
INFO Thread-11 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local439872970_0001
INFO Thread-11 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-11 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local439872970_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/ethonwu/Output.txt:0+76
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 8725; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26211584(104846336); length = 2813/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local439872970_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local439872970_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local439872970_0001_m_000000_0
INFO Thread-11 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-11 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local439872970_0001_r_000000_0
INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@255312ce
INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local439872970_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local439872970_0001_m_000000_0 decomp: 10135 len: 10139 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 10135 bytes from map-output for attempt_local439872970_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 10135, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->10135
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 10132 bytes
INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 10135 bytes to disk to satisfy reduce memory limit
INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 10139 bytes from disk
INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 10132 bytes
INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local439872970_0001_r_000000_0 is done. And is in the process of committing
INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local439872970_0001_r_000000_0 is allowed to commit now
INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local439872970_0001_r_000000_0' to hdfs://localhost:9000/ethonwu/output/_temporary/0/task_local439872970_0001_r_000000
INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local439872970_0001_r_000000_0' done.
INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local439872970_0001_r_000000_0
INFO Thread-11 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job - Job job_local439872970_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local439872970_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=20636
		FILE: Number of bytes written=537203
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1242
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=23
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=5
		Map output records=704
		Map output bytes=8725
		Map output materialized bytes=10139
		Input split bytes=105
		Combine input records=0
		Combine output records=0
		Reduce input groups=626
		Reduce shuffle bytes=10139
		Reduce input records=704
		Reduce output records=0
		Spilled Records=1408
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=15
		Total committed heap usage (bytes)=548405248
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=76
	File Output Format Counters 
		Bytes Written=0
WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobSubmitter - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local557998614_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local557998614_0001
INFO Thread-11 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-11 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-11 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local557998614_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/ethonwu/Output.txt:0+76
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 8725; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26211584(104846336); length = 2813/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local557998614_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local557998614_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local557998614_0001_m_000000_0
INFO Thread-11 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-11 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local557998614_0001_r_000000_0
INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2b22e873
INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local557998614_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local557998614_0001_m_000000_0 decomp: 10135 len: 10139 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 10135 bytes from map-output for attempt_local557998614_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 10135, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->10135
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 10132 bytes
INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 10135 bytes to disk to satisfy reduce memory limit
INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 10139 bytes from disk
INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 10132 bytes
INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local557998614_0001_r_000000_0 is done. And is in the process of committing
INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local557998614_0001_r_000000_0 is allowed to commit now
INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local557998614_0001_r_000000_0' to hdfs://localhost:9000/ethonwu/output/_temporary/0/task_local557998614_0001_r_000000
INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local557998614_0001_r_000000_0' done.
INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local557998614_0001_r_000000_0
INFO Thread-11 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job - Job job_local557998614_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local557998614_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=20636
		FILE: Number of bytes written=537203
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1242
		HDFS: Number of bytes written=111
		HDFS: Number of read operations=23
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=5
		Map output records=704
		Map output bytes=8725
		Map output materialized bytes=10139
		Input split bytes=105
		Combine input records=0
		Combine output records=0
		Reduce input groups=626
		Reduce shuffle bytes=10139
		Reduce input records=704
		Reduce output records=19
		Spilled Records=1408
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=4
		Total committed heap usage (bytes)=542113792
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=76
	File Output Format Counters 
		Bytes Written=111
WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobSubmitter - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local368308802_0001
INFO Thread-11 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-11 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local368308802_0001
INFO Thread-11 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local368308802_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/ethonwu/Output.txt:0+76
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 8725; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26211584(104846336); length = 2813/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local368308802_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local368308802_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local368308802_0001_m_000000_0
INFO Thread-11 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-11 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local368308802_0001_r_000000_0
INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3582848e
INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local368308802_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local368308802_0001_m_000000_0 decomp: 10135 len: 10139 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 10135 bytes from map-output for attempt_local368308802_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 10135, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->10135
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 10132 bytes
INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 10135 bytes to disk to satisfy reduce memory limit
INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 10139 bytes from disk
INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 10132 bytes
INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local368308802_0001_r_000000_0 is done. And is in the process of committing
INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local368308802_0001_r_000000_0 is allowed to commit now
INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local368308802_0001_r_000000_0' to hdfs://localhost:9000/ethonwu/output/_temporary/0/task_local368308802_0001_r_000000
INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local368308802_0001_r_000000_0' done.
INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local368308802_0001_r_000000_0
INFO Thread-11 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job - Job job_local368308802_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local368308802_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=20636
		FILE: Number of bytes written=537203
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1242
		HDFS: Number of bytes written=111
		HDFS: Number of read operations=23
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=5
		Map output records=704
		Map output bytes=8725
		Map output materialized bytes=10139
		Input split bytes=105
		Combine input records=0
		Combine output records=0
		Reduce input groups=626
		Reduce shuffle bytes=10139
		Reduce input records=704
		Reduce output records=19
		Spilled Records=1408
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=619708416
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=76
	File Output Format Counters 
		Bytes Written=111
